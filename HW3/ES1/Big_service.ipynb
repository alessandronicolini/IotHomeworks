{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cherrypy\n",
    "import json\n",
    "import base64\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocess audio bytes to mfcc\n",
    "sampling_rate = 16000\n",
    "frame_length = 640\n",
    "frame_step = 320\n",
    "lower_frequency = 20\n",
    "upper_frequency = 4000\n",
    "num_mel_bins = 40\n",
    "num_coefficients = 10\n",
    "num_spectrogram_bins = (frame_length) // 2 + 1\n",
    "\n",
    "linear_to_mel_weight_matrix = tf.signal.linear_to_mel_weight_matrix(num_mel_bins, num_spectrogram_bins, sampling_rate, \n",
    "                                                                    lower_frequency, upper_frequency)\n",
    "    \n",
    "def pad(audio):\n",
    "    zero_padding = tf.zeros([sampling_rate] - tf.shape(audio), dtype=tf.float32)\n",
    "    audio = tf.concat([audio, zero_padding], 0)\n",
    "    audio.set_shape([sampling_rate])\n",
    "    return audio\n",
    "\n",
    "def get_spectrogram(audio):\n",
    "    stft = tf.signal.stft(audio, frame_length=frame_length,\n",
    "    frame_step=frame_step, fft_length=frame_length)\n",
    "    spectrogram = tf.abs(stft)\n",
    "    return spectrogram\n",
    "\n",
    "def get_mfccs(spectrogram):\n",
    "    mel_spectrogram = tf.tensordot(spectrogram, linear_to_mel_weight_matrix, 1)\n",
    "    log_mel_spectrogram = tf.math.log(mel_spectrogram + 1.e-6)\n",
    "    mfccs = tf.signal.mfccs_from_log_mel_spectrograms(log_mel_spectrogram)\n",
    "    mfccs = mfccs[..., :num_coefficients]\n",
    "    return mfccs\n",
    "\n",
    "def process_audio(audio_binary):\n",
    "    audio, _ = tf.audio.decode_wav(audio_binary)\n",
    "    audio = tf.squeeze(audio, axis=1)\n",
    "    audio = pad(audio)\n",
    "    spectrogram = get_spectrogram(audio)\n",
    "    mfccs = get_mfccs(spectrogram)\n",
    "    mfccs = tf.expand_dims(mfccs, -1)\n",
    "    return mfccs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load tflite model from memory\n",
    "# Load TFLite model and allocate tensors.\n",
    "interpreter = tf.lite.Interpreter(model_path=\"big_model.tflite\")\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get input and output tensors.\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "\n",
    "input_shape = input_details[0]['shape']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myService(object):\n",
    "    exposed = True\n",
    "    \n",
    "    def GET(self, *path, **query):\n",
    "        \n",
    "        return(\"ciao\")\n",
    "    \n",
    "    def POST(self, *path, **query):\n",
    "        # receives a json containing a raw audio file\n",
    "        # reads the body of the http request\n",
    "        # processes the audio file as mfcc\n",
    "        # runs inference with big model using mfcc as input\n",
    "        # returns the values of the last layer of the neural network\n",
    "        \n",
    "        ##simplified version\n",
    "        \n",
    "        # read the http body and return a json string\n",
    "        req = cherrypy.request.body.read()\n",
    "        # convert the json string into python dictionary\n",
    "        body = json.loads(req)\n",
    "        audio_string = body[\"e\"][0][\"vd\"]\n",
    "        audio_binary = base64.b64decode(audio_string)\n",
    "        mfccs = process_audio(audio_binary)\n",
    "        mfccs = np.expand_dims(mfccs, axis=0).astype(np.float32)\n",
    "        interpreter.set_tensor(input_details[0]['index'], mfccs)\n",
    "        interpreter.invoke()\n",
    "        output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "        \n",
    "        return str(np.argmax(output_data))\n",
    "    \n",
    "    def PUT(self, *path, **query):\n",
    "        pass\n",
    "    \n",
    "    def DELETE(self, *path, **query):\n",
    "        pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    conf = {\n",
    "        '/': {\n",
    "            'request.dispatch': cherrypy.dispatch.MethodDispatcher(),\n",
    "            'tools.sessions.on': True,\n",
    "        }\n",
    "    }\n",
    "    cherrypy.tree.mount (myService(), \"/\",conf)\n",
    "    cherrypy.config.update({'server.socket_host': '127.0.0.1'})\n",
    "    cherrypy.config.update({'server.socket_port': 8080})\n",
    "    cherrypy.engine.start()\n",
    "    cherrypy.engine.block()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
