{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "continuous-curve",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import zlib\n",
    "import numpy as np\n",
    "import tempfile\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "from keras.optimizers.schedules import PolynomialDecay\n",
    "import keras\n",
    "\n",
    "import tensorflow_model_optimization as tfmot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "improved-hearts",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import SignalGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "empty-wings",
   "metadata": {},
   "outputs": [],
   "source": [
    "version = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "after-tradition",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-4-d9bca32e7fd5>, line 8)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-4-d9bca32e7fd5>\"\u001b[0;36m, line \u001b[0;32m8\u001b[0m\n\u001b[0;31m    x = keras.layers.Add()([x, s]).9062\u001b[0m\n\u001b[0m                                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def residual_block(x, filters, conv_num=3, activation=\"relu\"):\n",
    "    # Shortcut\n",
    "    s = keras.layers.Conv1D(filters, 1, padding=\"same\")(x)\n",
    "    for i in range(conv_num - 1):\n",
    "        x = keras.layers.Conv1D(filters, 3, padding=\"same\")(x)\n",
    "        x = keras.layers.Activation(activation)(x)\n",
    "    x = keras.layers.Conv1D(filters, 3, padding=\"same\")(x)\n",
    "    x = keras.layers.Add()([x, s]).9062 \n",
    "    x = keras.layers.Activation(activation)(x)\n",
    "    return keras.layers.MaxPool1D(pool_size=2, strides=2)(x)\n",
    "\n",
    "\n",
    "def build_model(input_shape, num_classes, conv1, conv2, conv3, conv4):\n",
    "    inputs = keras.layers.Input(shape=input_shape, name=\"input\")\n",
    "    new_inputs = tf.squeeze(inputs,3)\n",
    "    print(new_inputs.shape)\n",
    "    x = residual_block(new_inputs, 16, 2)\n",
    "    x = residual_block(x, conv1, 2)\n",
    "    x = residual_block(x, conv2, 3)\n",
    "    x = residual_block(x, conv3, 3)\n",
    "    x = residual_block(x, conv4, 3)\n",
    "\n",
    "    # x = keras.layers.MaxPooling1D()(x)#(pool_size=3, strides=3)(x)\n",
    "    x = keras.layers.Flatten()(x)\n",
    "    x = keras.layers.Dense(256, activation=\"relu\")(x)\n",
    "    x = keras.layers.Dense(128, activation=\"relu\")(x)\n",
    "\n",
    "    outputs = keras.layers.Dense(num_classes, name=\"output\")(x)\n",
    "\n",
    "    return keras.models.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "contrary-prospect",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_clustering(\n",
    "    in_model,\n",
    "    out_path,\n",
    "    epochs=4,\n",
    "    lr=1e-3,\n",
    "    n_clusters=12,\n",
    "    only_dense=False):\n",
    "\n",
    "    if only_dense:\n",
    "      def apply_clustering_to_dense(layer):\n",
    "        if isinstance(layer, tf.keras.layers.Dense):\n",
    "          return tfmot.clustering.keras.cluster_weights(\n",
    "              layer,\n",
    "              number_of_clusters=n_clusters,\n",
    "              cluster_centroids_init=tfmot.clustering.keras.CentroidInitialization.LINEAR\n",
    "              )\n",
    "        return layer\n",
    "\n",
    "      clustered_model = tf.keras.models.clone_model(\n",
    "          in_model,\n",
    "          clone_function = apply_clustering_to_dense)\n",
    "\n",
    "    else:\n",
    "      # create model for weight clustering\n",
    "      clustered_model = tfmot.clustering.keras.cluster_weights(\n",
    "          in_model,\n",
    "          number_of_clusters=n_clusters,\n",
    "          cluster_centroids_init=tfmot.clustering.keras.CentroidInitialization.LINEAR\n",
    "          )\n",
    "\n",
    "    # compile model\n",
    "    clustered_model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=lr),\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "        metrics=['sparse_categorical_accuracy']\n",
    "        )\n",
    "\n",
    "    # fit model\n",
    "    clustered_model.fit(\n",
    "        train_ds,\n",
    "        batch_size=32,\n",
    "        epochs=epochs,\n",
    "        validation_data=val_ds)\n",
    "\n",
    "    # clustered model evaluation\n",
    "    _, accuracy = clustered_model.evaluate(test_ds, verbose=0)\n",
    "\n",
    "    # prepare for export and save\n",
    "    model_for_export = tfmot.clustering.keras.strip_clustering(clustered_model)\n",
    "    #zip_size = save_model(model_for_export, out_path)\n",
    "\n",
    "    return model_for_export, accuracy\n",
    "\n",
    "\n",
    "\n",
    "# POST TRAINING QUANTIZATION ---------------------------------------------------\n",
    "def get_accuracy(interpreter, test_dataset):\n",
    "    input_index = interpreter.get_input_details()[0][\"index\"]\n",
    "    output_index = interpreter.get_output_details()[0][\"index\"]\n",
    "\n",
    "    running_corrects = 0\n",
    "    total_elements = 0\n",
    "\n",
    "    for (batch, labels) in test_dataset:\n",
    "        total_elements += len(batch)\n",
    "        for test_sample, label in  zip(batch, labels):\n",
    "            test_sample = np.expand_dims(test_sample, axis=0).astype(np.float32)\n",
    "            interpreter.set_tensor(input_index, test_sample)\n",
    "            interpreter.invoke()\n",
    "            output = interpreter.get_tensor(output_index)\n",
    "            pred = np.argmax(output)\n",
    "            if pred == label:\n",
    "              running_corrects += 1\n",
    "  \n",
    "    return running_corrects/total_elements\n",
    "\n",
    "def representative_dataset():\n",
    "  train_set = train_ds.unbatch().take(200)\n",
    "  img_list = []\n",
    "  for image in train_set:\n",
    "    img_list.append(image[0].numpy())\n",
    "  img_arr = np.array(img_list)\n",
    "\n",
    "  for data in tf.data.Dataset.from_tensor_slices(img_arr).batch(1).take(100):\n",
    "    yield [data]\n",
    "\n",
    "def pt_quantization(in_model, out_path, q_type='float16'):\n",
    "    converter = tf.lite.TFLiteConverter.from_keras_model(in_model)\n",
    "    if q_type == 'float16':\n",
    "      converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_LATENCY]\n",
    "      converter.target_spec.supported_types = [tf.float16]\n",
    "    elif q_type == 'int8int16':\n",
    "      converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_LATENCY]\n",
    "      converter.representative_dataset = representative_dataset\n",
    "      converter.target_spec.supported_ops = [tf.lite.OpsSet.EXPERIMENTAL_TFLITE_BUILTINS_ACTIVATIONS_INT16_WEIGHTS_INT8]\n",
    "    else:\n",
    "      converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "      converter.representative_dataset = representative_dataset\n",
    "      \n",
    "    quant_tflite_model = converter.convert()\n",
    "\n",
    "    # compressed file\n",
    "    compressed_model = zlib.compress(quant_tflite_model)\n",
    "    \n",
    "    compressed_file, c_filename = tempfile.mkstemp()\n",
    "\n",
    "\n",
    "    # generate compressed version    \n",
    "    with open(c_filename, 'wb') as f:\n",
    "        f.write(compressed_model)\n",
    "    \n",
    "    \n",
    "    interpreter = tf.lite.Interpreter(model_content=quant_tflite_model)\n",
    "    interpreter.allocate_tensors()\n",
    "    \n",
    "    accuracy = get_accuracy(interpreter, test_ds)\n",
    "    zip_size = os.path.getsize(c_filename)/1024\n",
    "    os.remove(c_filename)\n",
    "    \n",
    "    return accuracy, zip_size, quant_tflite_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "abroad-ceiling",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['down', 'stop', 'right', 'left', 'up', 'yes', 'no', 'go']\n"
     ]
    }
   ],
   "source": [
    "seed = 42\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "data_dir = pathlib.Path('data/mini_speech_commands')\n",
    "if not data_dir.exists():\n",
    "  tf.keras.utils.get_file(\n",
    "      'mini_speech_commands.zip',\n",
    "      origin=\"http://storage.googleapis.com/download.tensorflow.org/data/mini_speech_commands.zip\",\n",
    "      extract=True,\n",
    "      cache_dir='.', cache_subdir='data')\n",
    "\n",
    "#lista di training\n",
    "training_list=[]\n",
    "file=open(\"kws_train_split.txt\")\n",
    "for line in file:\n",
    "  training_list.append('.'+line[1:-1])\n",
    "\n",
    "#lista di validation\n",
    "validation_list=[]\n",
    "file=open(\"kws_val_split.txt\")\n",
    "for line in file:\n",
    "  validation_list.append('.'+line[1:-1])\n",
    "\n",
    "# lista di test\n",
    "test_list=[]\n",
    "file=open(\"kws_test_split.txt\")\n",
    "for line in file:\n",
    "  test_list.append('.'+line[1:-1])\n",
    "\n",
    "# lista di labels \n",
    "labels = open('labels.txt').readlines()[0].split() \n",
    "print(labels)\n",
    "\n",
    "\n",
    "MFCC_OPTIONS = {\n",
    "    'frame_length': 640, \n",
    "    'frame_step': 320, \n",
    "    'mfcc': True,\n",
    "    'lower_frequency': 20, \n",
    "    'upper_frequency': 4000, \n",
    "    'num_mel_bins': 40,\n",
    "    'num_coefficients': 10\n",
    "}\n",
    "\n",
    "# make test dataset\n",
    "generator = SignalGenerator(labels, 16000, **MFCC_OPTIONS) \n",
    "train_ds = generator.make_dataset(training_list, True)\n",
    "val_ds = generator.make_dataset(validation_list, False)\n",
    "test_ds = generator.make_dataset(test_list, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "instructional-batman",
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = [49, 10, 1]\n",
    "if version == 1:\n",
    "    model = models.Sequential([\n",
    "      layers.Input(shape=shape),\n",
    "      layers.Conv2D(filters=256, kernel_size=[3,3], strides=[2,1], use_bias=False),\n",
    "      layers.BatchNormalization(momentum=0.1),\n",
    "      layers.ReLU(),\n",
    "      layers.DepthwiseConv2D(kernel_size=[3,3], strides=[1,1], use_bias=False),\n",
    "      layers.Conv2D(filters=256, kernel_size=[1,1], strides=[1,1], use_bias=False),\n",
    "      layers.BatchNormalization(momentum=0.1),\n",
    "      layers.ReLU(),\n",
    "      layers.DepthwiseConv2D(kernel_size=[3,3], strides=[1,1], use_bias=False),\n",
    "      layers.Conv2D(filters=128, kernel_size=[1,1], strides=[1,1], use_bias=False),\n",
    "      layers.BatchNormalization(momentum=0.1),\n",
    "      layers.ReLU(),\n",
    "      layers.DepthwiseConv2D(kernel_size=[3,3], strides=[1,1], use_bias=False),\n",
    "      layers.Conv2D(filters=64, kernel_size=[1,1], strides=[1,1], use_bias=False),\n",
    "      layers.BatchNormalization(momentum=0.1),\n",
    "      layers.ReLU(),\n",
    "      layers.GlobalAveragePooling2D(),\n",
    "      layers.Dense(8)\n",
    "    ])\n",
    "elif version == 2:\n",
    "    model = models.Sequential([\n",
    "      layers.Input(shape=shape),\n",
    "      layers.Conv2D(filters=512, kernel_size=[3,3], strides=[2,1], use_bias=False),\n",
    "      layers.BatchNormalization(momentum=0.1),\n",
    "      layers.ReLU(),\n",
    "      layers.DepthwiseConv2D(kernel_size=[3,3], strides=[1,1], use_bias=False),\n",
    "      layers.Conv2D(filters=256, kernel_size=[1,1], strides=[1,1], use_bias=False),\n",
    "      layers.BatchNormalization(momentum=0.1),\n",
    "      layers.ReLU(),\n",
    "      layers.DepthwiseConv2D(kernel_size=[3,3], strides=[1,1], use_bias=False),\n",
    "      layers.Conv2D(filters=256, kernel_size=[1,1], strides=[1,1], use_bias=False),\n",
    "      layers.BatchNormalization(momentum=0.1),\n",
    "      layers.ReLU(),\n",
    "      layers.DepthwiseConv2D(kernel_size=[3,3], strides=[1,1], use_bias=False),\n",
    "      layers.Conv2D(filters=128, kernel_size=[1,1], strides=[1,1], use_bias=False),\n",
    "      layers.BatchNormalization(momentum=0.1),\n",
    "      layers.ReLU(),\n",
    "      layers.GlobalAveragePooling2D(),\n",
    "      layers.Dense(8)\n",
    "    ])\n",
    "elif version == 3:\n",
    "    model = models.Sequential([\n",
    "      layers.Input(shape=shape),\n",
    "      layers.Conv2D(filters=512, kernel_size=[3,3], strides=[2,1], use_bias=False),\n",
    "      layers.BatchNormalization(momentum=0.1),\n",
    "      layers.ReLU(),\n",
    "      layers.DepthwiseConv2D(kernel_size=[3,3], strides=[1,1], use_bias=False),\n",
    "      layers.Conv2D(filters=512, kernel_size=[1,1], strides=[1,1], use_bias=False),\n",
    "      layers.BatchNormalization(momentum=0.1),\n",
    "      layers.ReLU(),\n",
    "      layers.DepthwiseConv2D(kernel_size=[3,3], strides=[1,1], use_bias=False),\n",
    "      layers.Conv2D(filters=256, kernel_size=[1,1], strides=[1,1], use_bias=False),\n",
    "      layers.BatchNormalization(momentum=0.1),\n",
    "      layers.ReLU(),\n",
    "      layers.GlobalAveragePooling2D(),\n",
    "      layers.Dense(8)\n",
    "    ])\n",
    "elif version == 4:\n",
    "    conv_filters = {\n",
    "        \"conv1\": 32,\n",
    "        \"conv2\": 64,\n",
    "        \"conv3\": 128,\n",
    "        \"conv4\": 128\n",
    "    }\n",
    "    model = build_model(shape, 8, **conv_filters)\n",
    "elif version == 5:\n",
    "    conv_filters = {\n",
    "        \"conv1\": 32,\n",
    "        \"conv2\": 64,\n",
    "        \"conv3\": 128,\n",
    "        \"conv4\": 256\n",
    "    }\n",
    "    model = build_model(shape, 8, **conv_filters)\n",
    "else :\n",
    "    print(\"invalid input value!\")\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "spanish-leather",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 24, 8, 256)        2304      \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 24, 8, 256)        1024      \n",
      "_________________________________________________________________\n",
      "re_lu (ReLU)                 (None, 24, 8, 256)        0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d (DepthwiseC (None, 22, 6, 256)        2304      \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 22, 6, 256)        65536     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 22, 6, 256)        1024      \n",
      "_________________________________________________________________\n",
      "re_lu_1 (ReLU)               (None, 22, 6, 256)        0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_1 (Depthwis (None, 20, 4, 256)        2304      \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 20, 4, 128)        32768     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 20, 4, 128)        512       \n",
      "_________________________________________________________________\n",
      "re_lu_2 (ReLU)               (None, 20, 4, 128)        0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_2 (Depthwis (None, 18, 2, 128)        1152      \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 18, 2, 64)         8192      \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 18, 2, 64)         256       \n",
      "_________________________________________________________________\n",
      "re_lu_3 (ReLU)               (None, 18, 2, 64)         0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 8)                 520       \n",
      "=================================================================\n",
      "Total params: 117,896\n",
      "Trainable params: 116,488\n",
      "Non-trainable params: 1,408\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "200/200 [==============================] - 64s 183ms/step - loss: 1.5016 - sparse_categorical_accuracy: 0.4951 - val_loss: 0.6303 - val_sparse_categorical_accuracy: 0.8375\n",
      "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
      "Epoch 2/30\n",
      "200/200 [==============================] - 5s 23ms/step - loss: 0.5599 - sparse_categorical_accuracy: 0.8634 - val_loss: 0.4113 - val_sparse_categorical_accuracy: 0.8825\n",
      "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
      "Epoch 3/30\n",
      "200/200 [==============================] - 5s 23ms/step - loss: 0.3336 - sparse_categorical_accuracy: 0.9191 - val_loss: 0.3109 - val_sparse_categorical_accuracy: 0.9038\n",
      "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
      "Epoch 4/30\n",
      "200/200 [==============================] - 5s 23ms/step - loss: 0.2419 - sparse_categorical_accuracy: 0.9399 - val_loss: 0.2307 - val_sparse_categorical_accuracy: 0.9438\n",
      "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
      "Epoch 5/30\n",
      "200/200 [==============================] - 5s 23ms/step - loss: 0.1895 - sparse_categorical_accuracy: 0.9557 - val_loss: 0.2326 - val_sparse_categorical_accuracy: 0.9375\n",
      "Epoch 6/30\n",
      "200/200 [==============================] - 5s 23ms/step - loss: 0.1392 - sparse_categorical_accuracy: 0.9689 - val_loss: 0.2017 - val_sparse_categorical_accuracy: 0.9312\n",
      "Epoch 7/30\n",
      "200/200 [==============================] - 5s 23ms/step - loss: 0.1161 - sparse_categorical_accuracy: 0.9759 - val_loss: 0.2058 - val_sparse_categorical_accuracy: 0.9400\n",
      "Epoch 8/30\n",
      "200/200 [==============================] - 5s 23ms/step - loss: 0.0838 - sparse_categorical_accuracy: 0.9862 - val_loss: 0.1758 - val_sparse_categorical_accuracy: 0.9438\n",
      "Epoch 9/30\n",
      "200/200 [==============================] - 5s 23ms/step - loss: 0.0695 - sparse_categorical_accuracy: 0.9876 - val_loss: 0.1607 - val_sparse_categorical_accuracy: 0.9475\n",
      "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
      "Epoch 10/30\n",
      "200/200 [==============================] - 5s 23ms/step - loss: 0.0504 - sparse_categorical_accuracy: 0.9915 - val_loss: 0.1666 - val_sparse_categorical_accuracy: 0.9513\n",
      "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
      "Epoch 11/30\n",
      "200/200 [==============================] - 5s 23ms/step - loss: 0.0365 - sparse_categorical_accuracy: 0.9958 - val_loss: 0.1770 - val_sparse_categorical_accuracy: 0.9350\n",
      "Epoch 12/30\n",
      "200/200 [==============================] - 5s 23ms/step - loss: 0.0321 - sparse_categorical_accuracy: 0.9957 - val_loss: 0.1805 - val_sparse_categorical_accuracy: 0.9463\n",
      "Epoch 13/30\n",
      "200/200 [==============================] - 5s 23ms/step - loss: 0.0244 - sparse_categorical_accuracy: 0.9976 - val_loss: 0.1499 - val_sparse_categorical_accuracy: 0.9525\n",
      "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
      "Epoch 14/30\n",
      "200/200 [==============================] - 5s 23ms/step - loss: 0.0240 - sparse_categorical_accuracy: 0.9970 - val_loss: 0.1528 - val_sparse_categorical_accuracy: 0.9488\n",
      "Epoch 15/30\n",
      "200/200 [==============================] - 5s 23ms/step - loss: 0.0203 - sparse_categorical_accuracy: 0.9988 - val_loss: 0.1501 - val_sparse_categorical_accuracy: 0.9550\n",
      "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
      "Epoch 16/30\n",
      "200/200 [==============================] - 5s 23ms/step - loss: 0.0158 - sparse_categorical_accuracy: 0.9992 - val_loss: 0.1656 - val_sparse_categorical_accuracy: 0.9413\n",
      "Epoch 17/30\n",
      "200/200 [==============================] - 5s 23ms/step - loss: 0.0175 - sparse_categorical_accuracy: 0.9993 - val_loss: 0.1503 - val_sparse_categorical_accuracy: 0.9563\n",
      "INFO:tensorflow:Assets written to: ./checkpoint/assets\n",
      "Epoch 18/30\n",
      "200/200 [==============================] - 5s 23ms/step - loss: 0.0173 - sparse_categorical_accuracy: 0.9993 - val_loss: 0.1560 - val_sparse_categorical_accuracy: 0.9450\n",
      "Epoch 19/30\n",
      "200/200 [==============================] - 5s 23ms/step - loss: 0.0170 - sparse_categorical_accuracy: 0.9995 - val_loss: 0.1537 - val_sparse_categorical_accuracy: 0.9550\n",
      "Epoch 20/30\n",
      "200/200 [==============================] - 5s 23ms/step - loss: 0.0164 - sparse_categorical_accuracy: 0.9997 - val_loss: 0.1625 - val_sparse_categorical_accuracy: 0.9538\n",
      "Epoch 21/30\n",
      "200/200 [==============================] - 4s 22ms/step - loss: 0.0164 - sparse_categorical_accuracy: 0.9997 - val_loss: 0.1487 - val_sparse_categorical_accuracy: 0.9550\n",
      "Epoch 22/30\n",
      "200/200 [==============================] - 4s 22ms/step - loss: 0.0167 - sparse_categorical_accuracy: 0.9995 - val_loss: 0.1623 - val_sparse_categorical_accuracy: 0.9463\n",
      "Epoch 23/30\n",
      "200/200 [==============================] - 5s 23ms/step - loss: 0.0177 - sparse_categorical_accuracy: 0.9995 - val_loss: 0.1585 - val_sparse_categorical_accuracy: 0.9525\n",
      "Epoch 24/30\n",
      "200/200 [==============================] - 5s 23ms/step - loss: 0.0150 - sparse_categorical_accuracy: 0.9994 - val_loss: 0.1695 - val_sparse_categorical_accuracy: 0.9513\n",
      "Epoch 25/30\n",
      "200/200 [==============================] - 5s 23ms/step - loss: 0.0156 - sparse_categorical_accuracy: 0.9995 - val_loss: 0.1618 - val_sparse_categorical_accuracy: 0.9425\n",
      "Epoch 26/30\n",
      "200/200 [==============================] - 5s 23ms/step - loss: 0.0158 - sparse_categorical_accuracy: 0.9997 - val_loss: 0.1880 - val_sparse_categorical_accuracy: 0.9425\n",
      "Epoch 27/30\n",
      "200/200 [==============================] - 5s 23ms/step - loss: 0.0154 - sparse_categorical_accuracy: 0.9997 - val_loss: 0.1698 - val_sparse_categorical_accuracy: 0.9400\n",
      "Epoch 28/30\n",
      "200/200 [==============================] - 5s 23ms/step - loss: 0.0161 - sparse_categorical_accuracy: 0.9997 - val_loss: 0.1614 - val_sparse_categorical_accuracy: 0.9463\n",
      "Epoch 29/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 4s 22ms/step - loss: 0.0139 - sparse_categorical_accuracy: 0.9998 - val_loss: 0.1556 - val_sparse_categorical_accuracy: 0.9525\n",
      "Epoch 30/30\n",
      "200/200 [==============================] - 5s 23ms/step - loss: 0.0144 - sparse_categorical_accuracy: 0.9994 - val_loss: 0.1741 - val_sparse_categorical_accuracy: 0.9375\n",
      "25/25 [==============================] - 7s 271ms/step - loss: 0.1924 - sparse_categorical_accuracy: 0.9425\n",
      "\n",
      "sparse categorical accuracy on test set : 0.9424999952316284\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "\n",
    "# learning rate scheduler\n",
    "learning_rate_fn = PolynomialDecay(\n",
    "    initial_learning_rate=1e-3,\n",
    "    decay_steps=3000,\n",
    "    end_learning_rate=1e-5\n",
    "    )\n",
    "\n",
    "# compile model\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate_fn),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=['sparse_categorical_accuracy'],\n",
    ")\n",
    "\n",
    "# callbacks\n",
    "ckp_dir = \"./checkpoint/\"\n",
    "try:\n",
    "  os.mkdir(ckp_dir)\n",
    "except FileExistsError:\n",
    "  pass\n",
    "\n",
    "checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\n",
    "    ckp_dir, \n",
    "    monitor='val_sparse_categorical_accuracy', \n",
    "    verbose=0, \n",
    "    save_best_only=True,\n",
    "    save_weights_only=False, \n",
    "    mode='max', \n",
    "    save_freq='epoch')\n",
    "\n",
    "# fit model\n",
    "EPOCHS = 30\n",
    "history = model.fit(\n",
    "    train_ds, \n",
    "    validation_data=val_ds,  \n",
    "    epochs=EPOCHS,\n",
    "    callbacks=[checkpoint_cb],)\n",
    "\n",
    "# load and evaluate the best model\n",
    "base_model = tf.keras.models.load_model(ckp_dir)\n",
    "acc = base_model.evaluate(test_ds, batch_size=32, return_dict=True)['sparse_categorical_accuracy']\n",
    "print()\n",
    "print(\"sparse categorical accuracy on test set : \"+str(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "plain-addiction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "200/200 [==============================] - 5s 21ms/step - loss: 0.0593 - sparse_categorical_accuracy: 0.9804 - val_loss: 0.3078 - val_sparse_categorical_accuracy: 0.9212\n",
      "Epoch 2/4\n",
      "200/200 [==============================] - 4s 20ms/step - loss: 0.0714 - sparse_categorical_accuracy: 0.9756 - val_loss: 0.2046 - val_sparse_categorical_accuracy: 0.9475\n",
      "Epoch 3/4\n",
      "200/200 [==============================] - 4s 20ms/step - loss: 0.0611 - sparse_categorical_accuracy: 0.9776 - val_loss: 0.2566 - val_sparse_categorical_accuracy: 0.9375\n",
      "Epoch 4/4\n",
      "200/200 [==============================] - 4s 20ms/step - loss: 0.0372 - sparse_categorical_accuracy: 0.9857 - val_loss: 0.2700 - val_sparse_categorical_accuracy: 0.9400\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpyap7untj/assets\n",
      "accuracy of quantized model: 0.9012 %\n",
      "size of quantized model: 91.9941 kB\n"
     ]
    }
   ],
   "source": [
    "### OPTIMIZATIONS\n",
    "  \n",
    "out_path = \"model\"+str(version)\n",
    "\n",
    "quant_acc, quant_size, quant_model = pt_quantization(in_model=clustered_model, out_path=out_path, q_type='else')\n",
    "print('accuracy of quantized model: %.4f %%'%quant_acc)\n",
    "print('size of quantized model: %.4f kB'%quant_size)\n",
    "with open('model_'+str(version)+'.tflite', 'wb') as f:\n",
    "    f.write(quant_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "retained-jaguar",
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter = tf.lite.Interpreter(\"model_4.tflite\")\n",
    "interpreter.allocate_tensors()\n",
    "accuracy = get_accuracy(interpreter, test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "warming-botswana",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.89\n"
     ]
    }
   ],
   "source": [
    "print(accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
